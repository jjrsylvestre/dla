<?xml version="1.0" encoding="UTF-8" ?>

<section xml:id="section-linear-indep-activities">

<title>Activities</title>

<activity xml:id="activity-linear-indep-motivation">
  <statement>
    <p>
    Consider the vectors <m>\uvec{v}_1 = (1,0,1)</m>, <m>\uvec{v}_2 = (1,1,2)</m>, and <m>\uvec{v}_3 = (1,-1,0)</m>.
  	<ol label="alph">
  		<li xml:id="activity-linear-indep-motivation-recall-span">
      <p>
  		Do you remember what <m>\Span</m> means? Explain why the vector <m>\uvec{x} = 3\uvec{v}_1 + 2\uvec{v}_2 - \uvec{v}_3</m> is in <m>\Span \{\uvec{v}_1,\uvec{v}_2,\uvec{v}_3\}</m>.
      </p>
      <aside><title>Note</title><p>
      You can compute <m>\uvec{x}</m> if you like, but it is not necessary.
      </p></aside>
      </li>
      <li xml:id="activity-linear-indep-motivation-dependent">
      <p>
  		Actually, <m>\uvec{v}_2</m> can be expressed as a linear combination of <m>\uvec{v}_1</m> and <m>\uvec{v}_3</m> <mdash /> do you see how?
      </p><p>
  		Use this and the expression for <m>\uvec{x}</m> in the previous part of this activity to express <m>\uvec{x}</m> as a linear combination of <em>just</em> <m>\uvec{v}_1</m> and <m>\uvec{v}_3</m>.
      </p>
      </li>
  		<li>
      The previous part of this activity shows that <m>\uvec{x}</m> is in <m>\Span \{\uvec{v}_1,\uvec{v}_3\}</m>. Do you think that similar calculations and the same reasoning can be carried out for every vector in <m>\Span \{\uvec{v}_1,\uvec{v}_2,\uvec{v}_3\}</m>? What does this say about <m>\Span \{\uvec{v}_1,\uvec{v}_2,\uvec{v}_3\}</m> versus <m>\Span \{\uvec{v}_1,\uvec{v}_3\}</m>?
      </li>
  	</ol>
    </p>
  </statement>
</activity>

<activity>

  <prelude>
  <p>
  <xref ref="activity-linear-indep-motivation" /> demonstrates a common pattern: when one of the vectors in a spanning set can be expressed as a linear combination of the others, that vector becomes <em>redundant</em>, and a smaller spanning set can be used in place of the original one. We'll give this situation a name: a set of vectors is called <term>linearly dependent</term> if (at least) one of the vectors in the set can be written as a linear combination of other vectors in the set; otherwise the set of vectors is called <term>linearly independent</term>. However, it can be tedious to check each vector in a set one-by-one to see if it is a linear combination of others. Luckily, for a finite set of vectors, there is a way to check all of them all at once.
  </p>

  <paragraphs><title>Test for Linear Dependence/Independence</title>
  <p>
  To test whether vectors <m>\uvec{v}_1,\uvec{v}_2,\dotsc,\uvec{v}_m</m> are linearly dependent or independent, set up the vector equation
  <md><mrow tag="star" xml:id="equation-linear-indep-activities-test">
    k_1\uvec{v}_1 + k_2\uvec{v}_2 + \dotsb + k_m\uvec{v}_m = \zerovec,
  </mrow></md>
  where the coefficients <m>k_1,k_2,\dotsc,k_m</m> are (scalar) variables.
  <ul>
    <li> If vector equation <xref ref="equation-linear-indep-activities-test" /> has a nontrivial solution in the variables <m>k_1,k_2,\dotsc,k_m</m>, then the vectors <m>\uvec{v}_1,\uvec{v}_2,\dotsc,\uvec{v}_m</m> are <term>linearly dependent</term>. </li>
    <li> Otherwise, if vector equation <xref ref="equation-linear-indep-activities-test" /> has <em>only</em> the trivial solution <m>k_1=0,k_2=0,\dotsc,k_m=0</m>, then the vectors <m>\uvec{v}_1,\uvec{v}_2,\dotsc,\uvec{v}_m</m> are <term>linearly independent</term>. </li>
  </ul>
  </p></paragraphs>

  <aside><title>Check your understanding</title><p>
    Do you see why equation <xref ref="equation-linear-indep-activities-test" /> always has <em>at least</em> the trivial solution?
  </p></aside>

  </prelude>

  <statement>
    <p>
    <ol label="alph">
  		<li>
      <p>
      Use the test to verify that <m>\uvec{v}_1,\uvec{v}_2,\uvec{v}_3</m> from
      <xref ref="activity-linear-indep-motivation" />
      are linearly dependent.
      </p>
      <aside><title>Note</title><p>
  		  Vector equation <xref ref="equation-linear-indep-activities-test" /> should lead to a homogeneous linear system in the variables <m>k_1,k_2,\dotsc,k_m</m>. Look at the columns in your matrix for this system <mdash /> what do you notice?
      </p></aside>
      </li>
  		<li>
      Use the test to verify that <m>\uvec{v}_1,\uvec{v}_3</m> from
      <xref ref="activity-linear-indep-motivation" />
      are linearly independent.
      </li>
  	</ol>
    </p>
  </statement>
</activity>

<activity xml:id="activity-linear-indep-understand-test">

  <prelude><p>The next activity will help you understand the Test for Linear Independence/Dependence. To keep it simple, we'll consider just three vectors at a time.</p></prelude>

  <statement><p><ol label="alph">

    <li>
    <p>
    Consider abstract vectors <m>\uvec{u}_1,\uvec{u}_2,\uvec{u}_3</m>, and suppose the vector equation
    <md><mrow tag="dstar" xml:id="activity-linear-indep-understand-test-equation1">
      k_1\uvec{u}_1 + k_2\uvec{u}_2 + k_3\uvec{u}_3 = \zerovec
    </mrow></md>
    has a nontrivial solution. This means that there are values for the scalars <m>k_1,k_2,k_3</m>, at least one of which is not zero, so that equation <xref ref="activity-linear-indep-understand-test-equation1" /> is true.
    </p><p>
    Use some algebra to manipulate equation <xref ref="activity-linear-indep-understand-test-equation1" /> to demonstrate that one of the vectors can be expressed as a linear combination of the others (and hence, <em>by definition</em>, the vectors <m>\uvec{u}_1,\uvec{u}_2,\uvec{u}_3</m> are linearly dependent).
    </p>
    <aside><title>Careful</title><p> Make sure you don't accidentally divide by zero! </p></aside>
    </li>

    <li>
    <p>
    Consider abstract vectors <m>\uvec{w}_1,\uvec{w}_2,\uvec{w}_3</m>, and suppose the vector equation
    <md><mrow tag="tstar" xml:id="activity-linear-indep-understand-test-equation2">
      k_1\uvec{w}_1 + k_2\uvec{w}_2 + k_3\uvec{w}_3 = \zerovec
    </mrow></md>
    has <em>only</em> the trivial solution. We would like to see why this means that <m>\uvec{w}_1,\uvec{w}_2,\uvec{w}_3</m> are linearly independent.
    </p><p>
    Suppose they weren't: for example, suppose <m>\uvec{v}_3 = c_1\uvec{v}_1 + c_2\uvec{v}_2</m> were true for some scalars <m>c_1,c_2</m>. Manipulate this expression for <m>\uvec{v}_3</m> until is says something about equation
    <xref ref="activity-linear-indep-understand-test-equation2" />. Do you see now why <m>\uvec{v}_1,\uvec{v}_2,\uvec{v}_3</m> <em>cannot</em> satisfy the <em>definition</em> of linearly dependence, and hence must be linearly independent?
    </p>
    </li>

  </ol></p></statement>

</activity>

<activity xml:id="activity-linear-indep-using-indep-test">
  <statement><p>
    In each of the following vector spaces, practise using the Test for Linear Dependence/Independence of the given set of vectors.
  	<ol label="alph">

  		<li xml:id="activity-linear-indep-using-indep-test-M2-1">
  		<m>V = \matrixring_2(\R)</m>,
  		<m>S= \left\{\;
  			\begin{bmatrix} 1 \amp 0 \\ 0 \amp 1 \end{bmatrix}, \;\;
  			\begin{bmatrix} 0 \amp 1\\1 \amp 0 \end{bmatrix}, \;\;
  			\begin{bmatrix} 0 \amp 0\\0 \amp 1 \end{bmatrix} \;
  		\right\}
      </m>.
  		</li>

      <li xml:id="activity-linear-indep-using-indep-test-M2-2">
  		<m>V = \matrixring_2(\R)</m>,
  		<m>S= \left\{\;
  			\begin{bmatrix} 1 \amp 0 \\ 0 \amp 1 \end{bmatrix}, \;\;
  			\begin{bmatrix} 1 \amp 0 \\ 0 \amp -1 \end{bmatrix}, \;\;
  			\begin{bmatrix} 3 \amp 0 \\ 0 \amp -2 \end{bmatrix} \;
  		\right\}
      </m>.
      </li>

      <li xml:id="activity-linear-indep-using-indep-test-P2">
      <p>
      <m>V = \poly(\R)</m>,
  		<m>S = \{ 1+x, 1+x^2, 2 - x + 3x^2 \}</m>.
      </p>
      <hint><p>
  		After setting up the vector equation from the test for linear dependence/independence, you are solving for the scalars <m>k_1,k_2,k_3</m>, not for <m>x</m>. On the right-hand side, the zero represents the <em>zero vector</em>, which in this space is the <em>zero polynomial</em>. What are the coefficients on powers of <m>x</m> in the zero polynomial? The left-hand side, being equal, must have the same coefficients.
      </p></hint>
      </li>

  		<li> <m>V = \poly(\R)</m>, <m>S = \{ 1, x, x^2, x^3 \}</m>. </li>

  	</ol>
    </p></statement>
</activity>

<activity xml:id="activity-linear-indep-max-indep-in-R2-R3">
  <statement><p><ol label="alph">
		<li> Do you think it's possible to have a set of three linearly independent vectors in <m>\R^2</m>? Why or why not?</li>
		<li> Do you think it's possible to have a set of four linearly independent vectors in <m>\R^3</m>? Why or why not? </li>
	</ol></p></statement>
</activity>

<activity xml:id="activity-linear-indep-one-or-two">
  <statement><p><ol label="alph">
    <li> What does the definition of linear dependence say in the case of just two vectors? </li>
		<li> If the test for linear dependence/independence is to remain true in the case of a <q>set</q> of vectors consisting of just <em>one</em> vector, how should we define linear dependence/independence for such a set? </li>
  </ol></p></statement>
</activity>

</section>
